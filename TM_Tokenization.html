<!DOCTYPE html>
<html>

<head>
    <title>Tokenization</title>
    <link rel="stylesheet" href="CSS/style.css">
</head>

<body>
    <h1>Tokenization</h1>


    <h2>Introduction to Tokenization:</h2>
    <p>When we wish to extract some important information or insights from a given text, we use NLP approaches. However,
        we cannot execute NLP techniques on raw data, thus we must preprocess such data. Tokenization is one of the
        steps. It involves breaking down text into its constituent components, be it sentences, words, or even sub-words
        units. By converting textual data into manageable units, tokenization enables computers to grasp the structural
        and semantic aspects of language. In NLP, tokenization forms the foundation upon which tasks such as sentiment
        analysis, machine translation, and information retrieval are built, fostering a deeper understanding of human
        communication through computational means.
    </p>

    <h2>Tokenization Techniques:</h2>
    <ol>
        <li><strong>Sentence Tokenization: </strong>
            <ul>
                <li>
                    <p>Dividing text into coherent sentences for analysis.</p>
                </li>
                <li>
                    <p>Facilitating linguistic examination and comprehension.</p>
                </li>
            </ul>
        </li>
        <li><strong>Word Tokenization:</strong>
            <ul>
                <li>
                    <p>Breaking down sentences into individual words.</p>
                </li>
                <li>
                    <p>Enabling semantic understanding and language processing.</p>
                </li>
            </ul>
        </li>
        <li><strong>Sub-word Tokenization</strong>
            <ul>
                <li>
                    <p>Dealing with complex words and morphemes</p>
                </li>
                <li>
                    <p>Breaking them into smaller units for improved language modelling</p>
                </li>
            </ul>
        </li>

    </ol>


    <h2>Important Points Related with Tokenization </h2>
    <ol>
        <li>
            <p>Tokenization initiates NLP preprocessing by segmenting text into meaningful units.</p>
        </li>
        <li>
            <p>It serves as a foundational step, enabling structured analysis of textual data.</p>
        </li>
        <li>
            <p>Tokenization has a large impact on downstream tasks such as sentiment analysis, named entity recognition,
                language modelling, and machine translation. Tokenization improves the quality of collected insight as
                well as the performance of these tasks.</p>
        </li>

    </ol>
    <h3>Link of git code for Tokenization using NLTK:</h3>
    <ul>
        <li><a href="https://github.com/SaThorat/TMCodes/blob/main/tokenization.ipynb "
                target="_blank">https://github.com/SaThorat/TMCodes/blob/main/tokenization.ipynb </a>
        </li>
    </ul>
    <h3>References:</h3>
    <ul>
        <li><a href="https://neptune.ai/blog/tokenization-in-nlp"
                target="_blank">https://neptune.ai/blog/tokenization-in-nlp</a>
        </li>
        <li><a href="https://www.kaggle.com/code/satishgunjal/tokenization-in-nlp"
                target="_blank">https://www.kaggle.com/code/satishgunjal/tokenization-in-nlp</a>
        </li>
        <li><a href="https://www.tokenex.com/blog/ab-what-is-nlp-natural-language-processing-tokenization/"
                target="_blank">https://www.tokenex.com/blog/ab-what-is-nlp-natural-language-processing-tokenization/</a>
        </li>
    </ul>
    <h3>Contributed by:</h3>
    <ul>
        <li><a href="https://github.com/SaThorat" target="_blank">Dr. Sandeep Thorat</a></li>
        <li><a href="https://github.com/PiyushM109" target="_blank">Mr. Piyush More</a></li>
    </ul>
    <p style="text-align: end; color: black; font-size: large;"><a href="textMining.html" target="middleFrame">Go
            back</a></p>
</body>

</html>