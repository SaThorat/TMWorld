<!DOCTYPE html>
<html>
<head>
    <title>Types of Machine Learning Algorithms</title>
	<link rel="stylesheet" href="CSS/style.css">
</head>
<body>
	<h1>Types of Machine Learning Algorithms</h1>
    
    <p>Machine Learning algorithms can be categorized into several types based on their learning approach and the tasks they aim to solve. 
        Here are some common types of Machine Learning algorithms:</p>

    <h2>What is Text Mining?</h2>
    <p>Text mining is the process of transforming unstructured text data into structured form to identify meaningful patterns and insights. It involves various activities, starting with pre-processing the data, which includes cleaning and transforming it into a usable form. Some popular text mining techniques include Information Extraction (IE), Information Retrieval (IR), Natural Language Processing (NLP), Machine Learning, and Deep Learning. These techniques are used to perform various text mining tasks like Tokenization, Stemming, Feature selection, Feature extraction, Named Entity Recognition (NER), Part-of-Speech (PoS) tagging, Text annotation, Summarization, Sentiment analysis, Text categorization, and more.</p>

    <h2>Supervised Learning</h2>
    <p>These algorithms derive information from labelled training data in which the input and desired result are matched. The goal is to learn a mapping function that can predict the output for new and unseen inputs. Examples are as follows:</p>
    <ol>
        <li><strong>Linear Regression</strong> </li>
        <li><strong>Logistic Regression</strong> </li>
        <li><strong>Support Vector Machines</strong> </li>
        <li><strong>Decesion Tree</strong> </li>
        <li><strong>KNN Classifier</strong> </li>
        <li><strong>Random Forest</strong> </li>
        <li><strong>Naive Bayes</strong> </li>
    </ol>

    <h2>Unsupervised Learning</h2>
    <p>These algorithms operate on unlabelled data, trying to identify structures, correlations, or patterns. They are frequently employed for dimensionality reduction and clustering.
        Examples include:</p>
    <ol>
        <li><strong>Clustering Algorithms E.g. K-means, Hierarchical Clustering, Density-based Clustering etc. </strong> </li>
        <li><strong>Principal Component Analysis (PCA)</strong> </li>
        <li><strong>t-Distributed Stochastic Neighbour Embedding (t-SNE)</strong> </li>
        <li><strong>Generative Adversarial Networks (GANs)</strong> </li>
    </ol>

    <h2>Semi-Supervised Learning Algorithms</h2>
    <p>These algorithms combine elements of both supervised and unsupervised learning, using a small amount of labelled data along with a larger amount of unlabelled data. They are useful when obtaining large labelled datasets is challenging or expensive.</p>
    
    <h2>Reinforcement Learning</h2>
    <p>Reinforcement learning involves training agents to make sequential decisions in an environment to maximize a reward. The agent learns by interacting with the environment and receiving feedback. Examples are:</p>
    <ol>
        <li><strong>Q-Learning</strong> </li>
        <li><strong>Deep Q-Network (DQN)</strong> </li>
        <li><strong>Hidden Markov Model</strong> </li>
        <li><strong>Policy Gradient Methods</strong> </li>
        <li><strong>Actor-Ctitic Methods</strong> </li>
    </ol>

    <h2>Deep Learning</h2>
    <p>Deep learning involves neural networks with multiple layers (deep architectures) that can automatically learn hierarchical representations from data. Deep learning is very effective at jobs like voice and picture recognition. 
        Examples include:</p>
    <ol>
        <li><strong>Convolutional Neural Networks (CNN)</strong> </li>
        <li><strong>Recurrent Neural Networks (RNN)</strong> </li>
        <li><strong>Transformer Models (e.g., BERT, GPT)</strong> </li>
    </ol>


    <h2>Ensemble Methods</h2>
    <p>The predictions of various independent models are combined through ensemble techniques to enhance overall effectiveness and reduce over fitting. 
        Examples include:
        </p>
    <ol>
        <li><strong>Bagging (Bootstrap Aggregating)</strong> </li>
        <li><strong>Boosting (AdaBoost, Gradient Boosting)</strong> </li>
        <li><strong>Stacking</strong> </li>
    </ol>


    <h3>References:</h3>
    <ul>
        <li><a href="https://www.ibm.com/topics/text-mining" target="_blank">https://www.ibm.com/topics/text-mining</a></li>
        <li><a href="https://www.analyticsinsight.net/the-future-of-data-revolution-will-be-unstructured-data/" target="_blank">https://www.analyticsinsight.net/the-future-of-data-revolution-will-be-unstructured-data/</a></li>
        <li><a href="https://www.upgrad.com/blog/what-is-text-mining-techniques-and-applications/" target="_blank">https://www.upgrad.com/blog/what-is-text-mining-techniques-and-applications/</a></li>
    </ul>
	<h3>Contributed by:</h3>
	<ul>
		<li><a href="https://github.com/SaThorat" target="_blank">Dr. Sandeep Thorat</a></li>
	</ul>
	<p style="text-align: end; color: black; font-size: large;"><a href="textMining.html" target="middleFrame">Go back</a></p>
</body>
</html>
